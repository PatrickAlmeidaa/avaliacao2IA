{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d40e6ed",
   "metadata": {},
   "source": [
    "# Import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "f2d88303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab3aeb",
   "metadata": {},
   "source": [
    "# Variáveis das métricas dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "34663975",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr = []\n",
    "f1_lr = []\n",
    "acc_dt = []\n",
    "f1_dt = []\n",
    "acc_rf = []\n",
    "f1_rf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c7621",
   "metadata": {},
   "source": [
    "# Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "ba4af42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = pd.read_csv('falencia-treinamento.csv', delimiter=';')\n",
    "data_test = pd.read_csv('falencia-teste.csv', delimiter=';')\n",
    "data_result = pd.read_csv('modelo-submissao.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce8ff3",
   "metadata": {},
   "source": [
    "# Expansão do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "345b3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_training_copy = data_training.copy()\n",
    "# data_training_expanded = pd.concat([data_training, data_training_copy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3e23a",
   "metadata": {},
   "source": [
    "# Divisão do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "54bcfcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão do conjunto de dados falencia-treinamento em dados de treinamento e dados de teste. Divisão de 70% treinamento e 30% testes\n",
    "X_train_init, X_test_init, y_train_init, y_test_init = train_test_split(data_training.drop('Resultado', axis=1), data_training['Resultado'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1efc3",
   "metadata": {},
   "source": [
    "# Técnica Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "4c4f996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Técnica SMOTE para aplicar o Oversampling (criação de cópias da classe minoritária para que as classes fiquem equilibradas)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_init, y_train_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf716ca",
   "metadata": {},
   "source": [
    "# Seleção de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "7cb255c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Seleciona as características mais importantes para o modelo usando o teste qui-quadrado\n",
    "# selector = SelectKBest(chi2, k=10)\n",
    "# X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10015740",
   "metadata": {},
   "source": [
    "# Validação Cruzada (KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "205dbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "# for train_index, test_index in kf.split(X_train_resampled):\n",
    "#     # Split data into train and test sets\n",
    "#     X_train, X_test = X_train_resampled.iloc[train_index], X_train_resampled.iloc[test_index]\n",
    "#     y_train, y_test = y_train_resampled.iloc[train_index], y_train_resampled.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9905fba",
   "metadata": {},
   "source": [
    "# Seleção Univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "1a862e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector = SelectKBest(chi2, k=15)\n",
    "# X_new = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Obtém os índices dos recursos selecionados\n",
    "# selected_features = selector.get_support()\n",
    "\n",
    "# # Obtém os nomes dos recursos selecionados\n",
    "# selected_feature_names = X_train.columns[selected_features]\n",
    "\n",
    "# # Substitui as variáveis X_train e X_test pelos recursos selecionados\n",
    "# X_train_selected = X_train[selected_feature_names]\n",
    "# X_test_selected = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05d1d5",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "e0319a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cria um objeto RFE para selecionar 10 atributos\n",
    "# rfe = RFE(estimator=logistic_model, n_features_to_select=10)\n",
    "\n",
    "# # Ajusta o modelo aos dados de treinamento resampleados e seleciona os atributos\n",
    "# rfe.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Obtém os índices dos recursos selecionados\n",
    "# selected_features = rfe.support_\n",
    "\n",
    "# # Obtém os nomes dos recursos selecionados\n",
    "# selected_feature_names = X_train.columns[selected_features]\n",
    "\n",
    "# # Substitui as variáveis X_train e X_test pelos recursos selecionados pela RFE\n",
    "# X_train_selected = X_train[selected_feature_names]\n",
    "# X_test_selected = X_test[selected_feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50ef0f",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "5e942e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    # Cria um modelo de regressão logística\n",
    "    logistic_model = LogisticRegression(max_iter = 1000)\n",
    "    \n",
    "    # Ajusta o modelo aos dados de treinamento\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faz previsões nos dados de teste\n",
    "    y_pred_lr = logistic_model.predict(X_test)\n",
    "\n",
    "    # Calcula a acurácia do modelo nos dados de teste extraído dos de treinamento\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    f_measure_lr = f1_score(y_test, y_pred_lr)\n",
    "    \n",
    "    return accuracy_lr, f_measure_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d23712",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "97dab29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Cria um modelo de árvore de decisão com profundidade máxima de 3\n",
    "    tree_model = DecisionTreeClassifier(min_samples_split=3)\n",
    "\n",
    "    # Ajusta o modelo aos dados de treinamento\n",
    "    tree_model.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões nos dados de teste\n",
    "    y_pred_dt = tree_model.predict(X_test)\n",
    "\n",
    "    # Calcula a acurácia e f-measure do modelo nos dados de teste\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    f_measure_dt = f1_score(y_test, y_pred_dt)\n",
    "    \n",
    "    return accuracy_dt, f_measure_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769ba1a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "851445b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Cria um modelo de Random Forest com 100 árvores de decisão\n",
    "    rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Ajusta o modelo aos dados de treinamento\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Faz previsões nos dados de teste\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "    # Calcula a acurácia e f-measure do modelo nos dados de teste\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    f_measure_rf = f1_score(y_test, y_pred_rf)\n",
    "    \n",
    "    return accuracy_rf, f_measure_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ebb56",
   "metadata": {},
   "source": [
    "# Validação Cruzada (RepeatedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "65bef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = RepeatedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "\n",
    "accuracy_lr_list = []\n",
    "f_measure_lr_list = []\n",
    "accuracy_dt_list = []\n",
    "f_measure_dt_list = []\n",
    "accuracy_rf_list = []\n",
    "f_measure_rf_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_init):\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test = X_train_init.iloc[train_index], X_train_init.iloc[test_index]\n",
    "    y_train, y_test = y_train_init.iloc[train_index], y_train_init.iloc[test_index]\n",
    "    \n",
    "    # Regressão Logística\n",
    "    accuracy_lr, f_measure_lr = logistic_regression(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Árvore de Decisão\n",
    "    accuracy_dt, f_measure_dt = decision_tree(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Random Forest\n",
    "    accuracy_rf, f_measure_rf = random_forest(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    accuracy_lr_list.append(accuracy_lr)\n",
    "    f_measure_lr_list.append(f_measure_lr)\n",
    "    \n",
    "    accuracy_dt_list.append(accuracy_dt)\n",
    "    f_measure_dt_list.append(f_measure_dt)\n",
    "    \n",
    "    accuracy_rf_list.append(accuracy_rf)\n",
    "    f_measure_rf_list.append(f_measure_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b65fc6",
   "metadata": {},
   "source": [
    "# Avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "c29b075d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2567090417.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Mateus\\AppData\\Local\\Temp\\ipykernel_10632\\2567090417.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    print(f'Accuracy: {round(np.mean(accuracy_lr_list[i], 3))}\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Define as posições das barras\n",
    "models = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "x_pos = np.arange(len(models))\n",
    "x_pos = x_pos + 0.25\n",
    "\n",
    "# Plota o gráfico\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.bar(x_pos, [np.mean(accuracy_lr_list), np.mean(accuracy_dt_list), np.mean(accuracy_rf_list)], color='b', width=0.25)\n",
    "ax.bar(x_pos + 0.25, [np.mean(f_measure_lr_list), np.mean(f_measure_dt_list), np.mean(f_measure_rf_list)], color='g', width=0.25)\n",
    "ax.legend(['Acurácia', 'F-measure'])\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(models)\n",
    "\n",
    "# Exibe os valores finais\n",
    "print('Logistic Regression')\n",
    "print('Árvore de Decisão')\n",
    "print('Random Forest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
