{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78d2407",
   "metadata": {},
   "source": [
    "# Import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d88303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18aa70d",
   "metadata": {},
   "source": [
    "# Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba4af42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = pd.read_csv('falencia-treinamento.csv', delimiter=';')\n",
    "data_test = pd.read_csv('falencia-teste.csv', delimiter=';')\n",
    "data_result = pd.read_csv('modelo-submissao.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f174be69",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54bcfcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_training.drop('Resultado', axis=1), data_training['Resultado'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab65be",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e942e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de regressão logística é de 0.7375\n",
      "A F-measure do modelo de regressão logística é de 0.43243243243243246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=500)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Calcula a acurácia do modelo nos dados de teste extraído dos de treinamento\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "# resultados\n",
    "print(f'A acurácia do modelo de regressão logística é de {accuracy}')\n",
    "print(f\"A F-measure do modelo de regressão logística é de {f_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f29cb",
   "metadata": {},
   "source": [
    "# Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de96f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de árvore de decisão é de 0.725\n",
      "A F-measure do modelo de árvore de decisão é de 0.5217391304347826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criar um modelo de árvore de decisão com profundidade máxima de 3\n",
    "tree_model = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# ajustar o modelo aos dados de treinamento\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# fazer previsões nos dados de teste\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# calcular a acurácia e f-measure do modelo nos dados de teste\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "# resultados\n",
    "print(f\"A acurácia do modelo de árvore de decisão é de {accuracy}\")\n",
    "print(f\"A F-measure do modelo de árvore de decisão é de {f_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a783a1",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d4a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de Random Forest é de 0.75\n",
      "A F-measure do modelo de Random Forest é de 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# criar um modelo de Random Forest com 100 árvores de decisão\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# ajustar o modelo aos dados de treinamento\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# fazer previsões nos dados de teste\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# calcular a acurácia e f-measure do modelo nos dados de teste\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f_measure = f1_score(y_test, y_pred)\n",
    "\n",
    "# resultados\n",
    "print(f\"A acurácia do modelo de Random Forest é de {accuracy}\")\n",
    "print(f\"A F-measure do modelo de Random Forest é de {f_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55f6ae",
   "metadata": {},
   "source": [
    "# Comparação entre os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa72d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# calcular a acurácia e F-measure de cada modelo\n",
    "accuracy_lr, f_measure_lr = accuracy_score(y_test, y_pred_lr), f1_score(y_test, y_pred_lr)\n",
    "accuracy_dt, f_measure_dt = accuracy_score(y_test, y_pred_dt), f1_score(y_test, y_pred_dt)\n",
    "accuracy_rf, f_measure_rf = accuracy_score(y_test, y_pred_rf), f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# definir os rótulos do eixo x e os valores do eixo y\n",
    "labels = ['Regressão Logística', 'Árvore de Decisão', 'Random Forest']\n",
    "accuracy_values = [accuracy_lr, accuracy_dt, accuracy_rf]\n",
    "f_measure_values = [f_measure_lr, f_measure_dt, f_measure_rf]\n",
    "\n",
    "# definir a largura das barras\n",
    "bar_width = 0.35\n",
    "\n",
    "# definir a posição das barras no eixo x\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# criar o gráfico de barras\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - bar_width/2, accuracy_values, bar_width, label='Acurácia')\n",
    "rects2 = ax.bar(x + bar_width/2, f_measure_values, bar_width, label='F-measure')\n",
    "\n",
    "# adicionar rótulos, títulos e legendas ao gráfico\n",
    "ax.set_ylabel('Métrica')\n",
    "ax.set_title('Comparação de métricas entre modelos')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# exibir o gráfico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
